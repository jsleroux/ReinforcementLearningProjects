{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FrozenLake - Markov Decision Process.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsleroux/ReinforcementLearningProjects/blob/master/FrozenLake_Markov_Decision_Process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhzS-007iWKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDmks14YjaTa",
        "colab_type": "code",
        "outputId": "a6460ad1-7220-40e6-b2f2-31b14f2a0bd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1\n",
        "!pip install torch==1.0.0 > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XCwqhIbjb4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "\n",
        "gymlogger.set_level(40) #error only\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from collections import deque\n",
        "%matplotlib inline\n",
        "\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JwJQb9yje98",
        "colab_type": "code",
        "outputId": "54902c79-22af-45ac-87b1-55270138e907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tR5Wr4ujfPY",
        "colab_type": "code",
        "outputId": "8c7b4723-c8b8-4e75-aad5-5835621bafb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Start virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1024, 768))\n",
        "display.start()\n",
        "import os\n",
        "os.environ[\"DISPLAY\"] = \":\" + str(display.display) + \".\" + str(display.screen)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhQ0CRrdjh-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "    mp4list = glob.glob('video/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "                 </video>'''.format(encoded.decode('ascii'))))\n",
        "    else: \n",
        "        print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "    env = Monitor(env, './video', force=True)\n",
        "    return env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GaDTeV0mofl",
        "colab_type": "text"
      },
      "source": [
        "### Call the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmpIdA04jlKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = (gym.make(\"FrozenLake-v0\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdGukD7Xjj1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discount = 0.8\n",
        "epsilon = 1e-3\n",
        "\n",
        "\n",
        "values = np.zeros([e.env.observation_space.n])\n",
        "values[15] = 1\n",
        "\n",
        "termS = [5,7,11,12,15]\n",
        "\n",
        "e = env\n",
        "model = e.env.P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7dCEMa0ScNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "R = np.zeros([env.env.action_space.n, env.env.observation_space.n])\n",
        "R[:, 15] = 1\n",
        "\n",
        "\n",
        "T = np.zeros([env.action_space.n, env.observation_space.n, env.observation_space.n])\n",
        "for state in model:\n",
        "    for action in model[state]:\n",
        "        for nextstate in model[state][action]:\n",
        "            T[action, state, nextstate[1]] = nextstate[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az7GdixwkmJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getReward(rewards, state):\n",
        "    return rewards[state]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1NwEiwDCLU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeQValueFromValues(s, a):\n",
        "    qval = T[a, s, :].dot(R[a, :] + (discount*values_[:]))\n",
        "         \n",
        "    return qval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z1qccqT3sg2",
        "colab_type": "code",
        "outputId": "5610de63-03bc-40de-e7c9-f70d006df149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "i = 0\n",
        "while True:\n",
        "    i+=1\n",
        "    delta = 0\n",
        "    values_ = values.copy()\n",
        "    for state in range(e.observation_space.n):\n",
        "        allactionrewards = np.zeros([e.env.action_space.n])\n",
        "        for action in range(e.action_space.n):\n",
        "            allactionrewards[action] = computeQValueFromValues(state, action)\n",
        "        if state not in termS:\n",
        "            values[state] = allactionrewards.max()\n",
        "        \n",
        "        if np.abs(values[state]-values_[state]) > delta:\n",
        "            delta = np.abs(values[state]-values_[state])\n",
        "            \n",
        "    if delta < epsilon * (1 - discount) / discount:\n",
        "        break\n",
        "\n",
        "print('Learned in {} iterations'.format(i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learned in 22 iterations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP5uyREfFGaO",
        "colab_type": "code",
        "outputId": "22c1e24f-a6f6-4546-ee50-f6e70fbeb748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(values[0:4])\n",
        "print(values[4:8])\n",
        "print(values[8:12])\n",
        "print(values[12:16])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.02704473 0.02739048 0.04882192 0.0176735 ]\n",
            "[0.04760031 0.         0.10728956 0.        ]\n",
            "[0.10448939 0.24032175 0.3537701  0.        ]\n",
            "[0.         0.44338616 0.97934178 1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj3OyBvsuNzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfHKkwmIvtAW",
        "colab_type": "code",
        "outputId": "01884a46-a58b-44ec-93f3-c444fb417980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "# importing dependency libraries\n",
        "from __future__ import print_function\n",
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "#Load the environment\n",
        "env = gym.make('FrozenLake-v0')\n",
        "\n",
        "s = env.reset()\n",
        "print(s)\n",
        "print()\n",
        "\n",
        "env.render()\n",
        "print()\n",
        "\n",
        "print(env.action_space) #number of actions\n",
        "print(env.observation_space) #number of states\n",
        "print()\n",
        "\n",
        "print(\"Number of actions : \",env.action_space.n)\n",
        "print(\"Number of states : \",env.observation_space.n)\n",
        "print()\n",
        "\n",
        "# Value Iteration Implementation\n",
        "\n",
        "#Initializing Utilities of all states with zeros\n",
        "U = np.zeros([env.observation_space.n])\n",
        "\n",
        "#since terminal states have utility values equal to their reward\n",
        "U[15] = 1 #goal state\n",
        "U[[5,7,11,12]] = 0 #hole states\n",
        "termS = [5,7,11,12,15] #terminal states\n",
        "#set hyperparameters\n",
        "y = 0.8 #discount factor lambda\n",
        "\n",
        "eps = 1e-3 #threshold if the learning difference i.e. prev_u - U goes below this value break the learning\n",
        "\n",
        "i=0\n",
        "while(True):\n",
        "    i+=1\n",
        "    prev_u = np.copy(U)\n",
        "    for s in range(env.observation_space.n):\n",
        "        q_sa = [sum([p*(r + y*prev_u[s_]) for p, s_, r, _ in env.env.P[s][a]]) for a in range(env.action_space.n)]\n",
        "        if s not in termS: \n",
        "            U[s] = max(q_sa)\n",
        "            \n",
        "    if (np.sum(np.fabs(prev_u - U)) <= eps):\n",
        "        print ('Value-iteration converged at iteration# %d.' %(i+1))\n",
        "        break\n",
        "\n",
        "print(\"After learning completion printing the utilities for each states below from state ids 0-15\")\n",
        "print()\n",
        "print(U[:4])\n",
        "print(U[4:8])\n",
        "print(U[8:12])\n",
        "print(U[12:16])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "\n",
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "\n",
            "Discrete(4)\n",
            "Discrete(16)\n",
            "\n",
            "Number of actions :  4\n",
            "Number of states :  16\n",
            "\n",
            "Value-iteration converged at iteration# 25.\n",
            "After learning completion printing the utilities for each states below from state ids 0-15\n",
            "\n",
            "[0.02739138 0.02774255 0.04918606 0.02798151]\n",
            "[0.0479302  0.         0.10746661 0.        ]\n",
            "[0.10477919 0.24054144 0.35393967 0.        ]\n",
            "[0.         0.44355711 0.9794359  1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM3sUrmnAg7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aB9TifuTaRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}