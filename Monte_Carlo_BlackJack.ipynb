{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Monte Carlo - BlackJack",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsleroux/ReinforcementLearningProjects/blob/master/Monte_Carlo_BlackJack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6PGSTAs-9t2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSDYH0er_D_j",
        "colab_type": "code",
        "outputId": "4590c7a7-0dee-4dc2-b7e9-998db83fb541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1\n",
        "#!pip install torch==1.0.0 > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GowB6uZWDNQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "\n",
        "gymlogger.set_level(40) #error only\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from collections import deque\n",
        "%matplotlib inline\n",
        "\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from mpl_toolkits import mplot3d\n",
        "#from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSAoNs1o87Dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Counter(dict):\n",
        "    # dictionary that returns zero for missing keys\n",
        "    # keys with zero values are not stored\n",
        "\n",
        "    def __missing__(self,key):\n",
        "        return 0\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        if value==0:\n",
        "            if key in self:  # returns zero anyway, so no need to store it\n",
        "                del self[key]\n",
        "        else:\n",
        "            dict.__setitem__(self, key, value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dALp4eoC_Fke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('Blackjack-v0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLlmltVE9XLD",
        "colab_type": "code",
        "outputId": "ee011a57-b3b7-4c0d-af80-af68f65a70a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "env.observation_space"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tuple(Discrete(32), Discrete(11), Discrete(2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvEm3Crq44Px",
        "colab_type": "text"
      },
      "source": [
        "### Monte Carlo Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TdyhIrvfLPU",
        "colab_type": "text"
      },
      "source": [
        "##### First-visit MC prediction, for estimating V"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbguXT84SsMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_stick20up():\n",
        "    policy = np.zeros([32, 11, 2], dtype='int')\n",
        "\n",
        "    policy[0:20, :, :] = 1\n",
        "    policy[20:, :, :] = 0\n",
        "    \n",
        "    return policy\n",
        "\n",
        "pi = generate_stick20up()\n",
        "assert pi.shape == (32, 11, 2), \"Policy has invalid shape\"\n",
        "assert pi[20:, :, :].sum() == 0, \"Invalid policy. Actions must only be stick (0)\"\n",
        "assert np.sum(pi[0:19, :, :]!=1)==0, 'Invalid policy. Actions must only be hit(1)'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnbRXu4L-t3v",
        "colab_type": "code",
        "outputId": "ea1bb08a-deb4-41c0-fae5-c6c9b89c0c6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "env.reset()\n",
        "runs = 500000\n",
        "gamma = 1\n",
        "counter = Counter()\n",
        "V = np.zeros([32, 11, 2])\n",
        "\n",
        "    \n",
        "for run in range(runs):\n",
        "    episode = [] # Resets episode\n",
        "    done = False # Not initialized when nhands = 1\n",
        "    reward = 0   # Not initialized when nhands = 1\n",
        "    nhands = 0   # Number of blackjack hands\n",
        "    action = -1  # No action for the initial hand\n",
        "    \n",
        "    # Generate an episode from a policy\n",
        "    while True:  \n",
        "        if nhands == 0:\n",
        "            state = env.reset()\n",
        "        else:\n",
        "            action = pi[mycount, hiscount, ace]\n",
        "            state, reward, done, _ = env.step(action)\n",
        "        \n",
        "        nhands+=1\n",
        "        \n",
        "        mycount, hiscount, ace = state\n",
        "        ace = 0 if ace is False else 1 # Quick hack, observation is boolean, we need 0 or 1\n",
        "        \n",
        "        episode.append((state, action, reward))\n",
        "\n",
        "        if done == True:\n",
        "            break\n",
        "\n",
        "    g = 0\n",
        "    done_steps_of_episode = [] # first visit MC\n",
        "        \n",
        "    # We reverse the episode because MC predictions works the episode\n",
        "    # starting from the end ...\n",
        "    episode.reverse()\n",
        "    for (state, action, reward) in episode:\n",
        "        mycount, hiscount, ace = state\n",
        "        ace = 0 if ace is False else 1\n",
        "        \n",
        "        g = (gamma * g) + reward\n",
        "        # This condition is there for first visit MC\n",
        "        if state not in done_steps_of_episode:\n",
        "            counter[state]+=1                                \n",
        "            V[mycount, hiscount, ace] = V[mycount, hiscount, ace] + 1/counter[state]*(g - V[mycount, hiscount, ace])\n",
        "\n",
        "        done_steps_of_episode.append(state)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 23.8 s, sys: 182 Âµs, total: 23.8 s\n",
            "Wall time: 23.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eWO4TXb4-Tl",
        "colab_type": "text"
      },
      "source": [
        "### Create data for graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcToNPaDvbbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterables = [range(V.shape[0]), range(V.shape[1])]\n",
        "index = pd.MultiIndex.from_product(iterables, names=['mycount', 'hiscount'])\n",
        "df = pd.DataFrame(index=index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNXVBazvf-6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for mycount in range(V.shape[0]):\n",
        "    for hiscount in range(V.shape[1]):\n",
        "        df.loc[(mycount, hiscount), 'V'] = V[mycount, hiscount, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHbicDD3wkby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DEjviPM5EM7",
        "colab_type": "text"
      },
      "source": [
        "### Plot Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2-yXJRGf-y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax = plt.axes(projection='3d')\n",
        "ax.set_zlim([-1,1])\n",
        "df = df[(df['mycount']>=12)&(df['mycount']<=21)]\n",
        "df = df[(df['hiscount']>0)]\n",
        "ax.plot_trisurf(df['hiscount'], df['mycount'], df['V'], cmap='viridis')#, rstride=1, cstride=1, cmap='viridis', edgecolor='none')\n",
        "ax.set_title('Approximate state-value functions for blackjack policy that sticks at 20 and 21')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK8WtWxyfRnE",
        "colab_type": "text"
      },
      "source": [
        "##### On-policy first-visit MC control (for e-soft policies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EPjjblRobbv",
        "colab_type": "text"
      },
      "source": [
        "#### todo\n",
        "- small error, 3rd arguments of policy are not actions, but usable ace\n",
        "- also, adapt V array to contains action values and not only values of state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_YEFyhik0pV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_arbitrary():\n",
        "    policy = np.zeros([32, 11, 2, 2]) # mycount, hiscount, ace, action\n",
        "\n",
        "    policy[:, :, :, :] = 0.5\n",
        "    \n",
        "    return policy\n",
        "\n",
        "pi = generate_arbitrary()\n",
        "assert pi.shape == (32, 11, 2, 2), \"Policy has invalid shape\"\n",
        "assert np.all(pi.sum(axis=3)==1), \"Actions probabilities don't sum to 1\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpGdLM8ZfQ-1",
        "colab_type": "code",
        "outputId": "a5a31362-776b-456a-dd09-a07ef7ebaa90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "env.reset()\n",
        "runs = 500000\n",
        "gamma = 1\n",
        "epsilon = 0.6\n",
        "counter = Counter()\n",
        "V = np.zeros([32, 11, 2, 2]) # mycount, hiscount, ace, action\n",
        "\n",
        "    \n",
        "for run in range(runs):\n",
        "    episode = [] # Resets episode\n",
        "    done = False # Not initialized when nhands = 1\n",
        "    reward = 0   # Not initialized when nhands = 1\n",
        "    nhands = 0   # Number of blackjack hands\n",
        "    action = -1  # No action for the initial hand\n",
        "    \n",
        "    # Generate an episode from a policy\n",
        "    while True:  \n",
        "        if nhands == 0:\n",
        "            state = env.reset()\n",
        "        else:\n",
        "            # argmax with tiebreaking\n",
        "            action = np.random.choice(np.flatnonzero(pi[mycount, hiscount, ace] == pi[mycount, hiscount, ace].max()))\n",
        "            \n",
        "            state, reward, done, _ = env.step(action)\n",
        "        \n",
        "        nhands+=1\n",
        "        \n",
        "        mycount, hiscount, ace = state\n",
        "        ace = 0 if ace is False else 1 # Quick hack, observation is boolean, we need 0 or 1\n",
        "        \n",
        "        episode.append((state, action, reward))\n",
        "\n",
        "        if done == True:\n",
        "            break\n",
        "\n",
        "    g = 0\n",
        "    done_steps_of_episode = [] # first visit MC\n",
        "        \n",
        "    # We reverse the episode because MC predictions works the episode\n",
        "    # starting from the end ...\n",
        "    episode.reverse()\n",
        "    for (state, action, reward) in episode:\n",
        "        mycount, hiscount, ace = state\n",
        "        ace = 0 if ace is False else 1\n",
        "        \n",
        "        g = (gamma * g) + reward\n",
        "        # This condition is there for first visit MC\n",
        "        if (state, action) not in done_steps_of_episode:\n",
        "            counter[(state, action)] += 1             \n",
        "            \n",
        "            V[mycount, hiscount, ace, action] = V[mycount, hiscount, ace, action] + (1 / counter[(state, action)]) * (g - V[mycount, hiscount, ace, action])\n",
        "            \n",
        "            a_ = np.random.choice(np.flatnonzero(V[mycount, hiscount, ace] == V[mycount, hiscount, ace].max()))\n",
        "            for a in range(env.action_space.n):\n",
        "                if a == a_:\n",
        "                    pi[mycount, hiscount, ace, a] = 1 - epsilon + (epsilon / env.action_space.n)\n",
        "                else:\n",
        "                    pi[mycount, hiscount, ace, a] = (epsilon / env.action_space.n)\n",
        "                \n",
        "\n",
        "        done_steps_of_episode.append((state, action))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min, sys: 385 ms, total: 1min\n",
            "Wall time: 1min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8znjZEhXncP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert np.argmax(V[20, 6, 1, :]) == 0, 'Policy should be stick'\n",
        "assert np.argmax(V[15, 6, 1, :]) == 1, 'Policy should be hit'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWedCn4QfjHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}